{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7312913c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mohamed-stifi/Desktop/pfa-s4/notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e05c0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mohamed-stifi/Desktop/pfa-s4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d980a6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mohamed-stifi/Desktop/pfa-s4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed-stifi/Desktop/pfa-s4/pfa-venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from text_classifier.components.model_trainer import TextDataset, ModelTrainer\n",
    "from text_classifier.config.configuration import ConfigurationManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d94af31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-29 17:53:34,559: INFO: common: text_classifier.utils.common: yaml file: /home/mohamed-stifi/Desktop/pfa-s4/config/config.yaml loaded successfully]\n",
      "[2025-05-29 17:53:34,575: INFO: common: text_classifier.utils.common: yaml file: /home/mohamed-stifi/Desktop/pfa-s4/config/params.yaml loaded successfully]\n",
      "[2025-05-29 17:53:34,579: INFO: common: text_classifier.utils.common: created directory at: artifacts]\n",
      "[2025-05-29 17:53:34,581: INFO: common: text_classifier.utils.common: created directory at: artifacts/model_trainer]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelTrainerConfig(root_dir='artifacts/model_trainer', data_path='artifacts/data_transformation', model_name='bert-base-uncased', num_train_epochs=5, warmup_ratio=0.1, per_device_train_batch_size=16, per_device_eval_batch_size=16, weight_decay=0.01, logging_steps=10, evaluation_strategy='epoch', eval_steps=500, save_steps=500, gradient_accumulation_steps=1, learning_rate=2e-05)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "\n",
    "model_trainer_config = config.get_model_trainer_config()\n",
    "model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<text_classifier.components.model_trainer.ModelTrainer at 0x72d70c45b320>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trainer = ModelTrainer(model_trainer_config)\n",
    "\n",
    "model_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_classifier.components.model_evaluation import ModelEvaluation\n",
    "from text_classifier.config.configuration import ConfigurationManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c83ae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-29 17:53:38,033: INFO: common: text_classifier.utils.common: yaml file: /home/mohamed-stifi/Desktop/pfa-s4/config/config.yaml loaded successfully]\n",
      "[2025-05-29 17:53:38,053: INFO: common: text_classifier.utils.common: yaml file: /home/mohamed-stifi/Desktop/pfa-s4/config/params.yaml loaded successfully]\n",
      "[2025-05-29 17:53:38,058: INFO: common: text_classifier.utils.common: created directory at: artifacts]\n",
      "[2025-05-29 17:53:38,061: INFO: common: text_classifier.utils.common: created directory at: artifacts/model_evaluation]\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "model_evaluation_config = config.get_model_evaluation_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b200efbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelEvaluationConfig(root_dir='artifacts/model_evaluation', data_path='artifacts/data_transformation', comparison_file='artifacts/model_trainer/model_comparison.json', metric_file_name='artifacts/model_evaluation/evaluation_report.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de5a400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<text_classifier.components.model_evaluation.ModelEvaluation at 0x72d70c459d30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation = ModelEvaluation(model_evaluation_config)\n",
    "model_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9643c83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ModelEvaluation in module text_classifier.components.model_evaluation object:\n",
      "\n",
      "class ModelEvaluation(builtins.object)\n",
      " |  ModelEvaluation(config: text_classifier.entity.config_entity.ModelEvaluationConfig)\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, config: text_classifier.entity.config_entity.ModelEvaluationConfig)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  evaluate_all_models(self, data_loader_fun)\n",
      " |      Evaluate all trained models\n",
      " |\n",
      " |  evaluate_model(self, model, test_loader, model_name)\n",
      " |      Evaluate a single model\n",
      " |\n",
      " |  generate_evaluation_report(self, results_dict)\n",
      " |      Generate comprehensive evaluation report\n",
      " |\n",
      " |  load_model(self, model_path, model_type)\n",
      " |      Load trained model from checkpoint\n",
      " |\n",
      " |  plot_confusion_matrix(self, cm, model_name, save_path)\n",
      " |      Plot and save confusion matrix\n",
      " |\n",
      " |  plot_model_comparison(self, results_dict, save_path)\n",
      " |      Plot model comparison chart\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b081da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_fun = model_trainer.prepare_data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "702b5e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-29 17:53:53,771: INFO: model_evaluation: textClassifierLogger: Starting model evaluation...]\n",
      "[2025-05-29 17:53:53,776: INFO: model_evaluation: textClassifierLogger: Evaluating lstm...]\n",
      "[2025-05-29 17:53:57,569: INFO: model_evaluation: textClassifierLogger: lstm evaluation completed]\n",
      "[2025-05-29 17:53:57,574: INFO: model_evaluation: textClassifierLogger: Accuracy: 0.8250]\n",
      "[2025-05-29 17:53:57,576: INFO: model_evaluation: textClassifierLogger: Evaluating bert...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed-stifi/Desktop/pfa-s4/pfa-venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mohamed-stifi/Desktop/pfa-s4/pfa-venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mohamed-stifi/Desktop/pfa-s4/pfa-venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mohamed-stifi/Desktop/pfa-s4/pfa-venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-29 17:54:46,918: INFO: model_evaluation: textClassifierLogger: bert evaluation completed]\n",
      "[2025-05-29 17:54:46,919: INFO: model_evaluation: textClassifierLogger: Accuracy: 0.5000]\n",
      "[2025-05-29 17:54:46,921: INFO: model_evaluation: textClassifierLogger: Evaluating roberta...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/mohamed-stifi/Desktop/pfa-s4/pfa-venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mohamed-stifi/Desktop/pfa-s4/pfa-venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mohamed-stifi/Desktop/pfa-s4/pfa-venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mohamed-stifi/Desktop/pfa-s4/pfa-venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-29 17:57:35,133: INFO: model_evaluation: textClassifierLogger: roberta evaluation completed]\n",
      "[2025-05-29 17:57:35,143: INFO: model_evaluation: textClassifierLogger: Accuracy: 0.5000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/29 17:57:36 INFO mlflow.tracking.fluent: Experiment with name 'model_evaluation' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-29 17:57:36,820: INFO: model_evaluation: textClassifierLogger: Evaluation completed. Best model: lstm]\n"
     ]
    }
   ],
   "source": [
    "evaluation_report = model_evaluation.evaluate_all_models(data_loader_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3f0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfa-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
